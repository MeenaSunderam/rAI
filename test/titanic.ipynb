{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "Requirement already satisfied: codecarbon in /opt/conda/lib/python3.7/site-packages (2.0.0)\n",
      "Requirement already satisfied: fuzzywuzzy in /opt/conda/lib/python3.7/site-packages (from codecarbon) (0.18.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from codecarbon) (2.27.1)\n",
      "Requirement already satisfied: arrow in /opt/conda/lib/python3.7/site-packages (from codecarbon) (1.2.2)\n",
      "Requirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.7/site-packages (from codecarbon) (8.0.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from codecarbon) (1.0.1)\n",
      "Requirement already satisfied: pynvml in /opt/conda/lib/python3.7/site-packages (from codecarbon) (11.4.1)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from codecarbon) (7.0)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.7/site-packages (from codecarbon) (5.6.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7.0 in /opt/conda/lib/python3.7/site-packages (from arrow->codecarbon) (2.8.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from arrow->codecarbon) (4.1.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.7/site-packages (from pandas->codecarbon) (2019.3)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /opt/conda/lib/python3.7/site-packages (from pandas->codecarbon) (1.21.5)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests->codecarbon) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->codecarbon) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->codecarbon) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->codecarbon) (2021.10.8)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.0->arrow->codecarbon) (1.14.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install codecarbon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "Requirement already satisfied: captum in /opt/conda/lib/python3.7/site-packages (0.5.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from captum) (1.21.5)\n",
      "Requirement already satisfied: torch>=1.6 in /opt/conda/lib/python3.7/site-packages (from captum) (1.11.0)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from captum) (3.1.3)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.6->captum) (4.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->captum) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->captum) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->captum) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->captum) (2.4.6)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from cycler>=0.10->matplotlib->captum) (1.14.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib->captum) (62.0.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install captum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import logging\n",
    "from codecarbon import EmissionsTracker as ET\n",
    "from opacus import PrivacyEngine \n",
    "from captum.attr import IntegratedGradients\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "class responsibleModel:\n",
    "    \n",
    "    __modelname__ = \"\"\n",
    "    __framework__ = \"\"\n",
    "    __emissions__ = 0.0\n",
    "    __classbalance__ = 0.0\n",
    "    __interpretable_degree__ = 0.0\n",
    "    __epsilon__ = 0.0\n",
    "    __tracker__ = None\n",
    "    __privacy_engine__ = None\n",
    "    \n",
    "    def __init__(self,):\n",
    "        self.__modelname__ = \"\"\n",
    "        self.__framework__ = \"\"\n",
    "        self.__emissions__ = 0.0\n",
    "        self.__classbalance__ = 0.0\n",
    "        self.__interpretable_degree__ = 0.0\n",
    "        self.__epsilon__ = 0.0\n",
    "        \n",
    "        self.__tracker__ = ET(project_name = \"\",\n",
    "            measure_power_secs = 15,\n",
    "            save_to_file = False)\n",
    "        \n",
    "        self.__privacy_engine__ = PrivacyEngine()\n",
    "\n",
    "    def __init__(self, \n",
    "                 modelname: str,\n",
    "                 framework:str,\n",
    "                 interpretable_degree:float = 0.0,\n",
    "                 emissions:float = 0.0,\n",
    "                 classbalance:float= 0.0,\n",
    "                 epsilon:float = 0.0):\n",
    "        \n",
    "        self.__modelname__ = modelname\n",
    "        self.__framework__ = framework\n",
    "        self.__emissions__ = emissions\n",
    "        self.__classbalance__ = classbalance\n",
    "        self.__interpretable_degree__ = interpretable_degree\n",
    "        self.__epsilon__ = epsilon\n",
    "    \n",
    "        self.__tracker__ = ET(project_name = modelname,\n",
    "            measure_power_secs = 15,\n",
    "            save_to_file = False)\n",
    "        \n",
    "        self.__privacy_engine__ = PrivacyEngine()\n",
    "    \n",
    "    def set_interpretability(self, interpretable_degree: float):\n",
    "        self.__interpretable_degree__ = interpretable_degree\n",
    "\n",
    "    def set_emissions(self, carbon_emissions: float):\n",
    "        self.__emissions__ = carbon_emissions\n",
    "\n",
    "    def set_classbalance(self, minclass: float):\n",
    "        self.__classbalance__ = minclass\n",
    "\n",
    "    def set_epsilon(self, privacy_epsilon: bool):\n",
    "        self.__epsilon__ = privacy_epsilon\n",
    "\n",
    "    def set_framework(self, framework: str):\n",
    "        self.__framework__ = framework\n",
    "        \n",
    "    def calculate_emissions_index(self):\n",
    "\n",
    "        if self.__emissions__ <= 500:\n",
    "            emissionIndex = 3\n",
    "        elif self.__emissions__ > 500 and self.__emissions__ <= 10000:\n",
    "            emissionIndex = 2\n",
    "        else:\n",
    "            emissionIndex = 1\n",
    "\n",
    "        return emissionIndex\n",
    "\n",
    "    def calculate_privacy_index(self):\n",
    "        if self.__epsilon__ <= 1:\n",
    "            privacyIndex = 3\n",
    "        elif self.__epsilon__ > 1 and self.__epsilon__ <= 10:\n",
    "            privacyIndex = 2\n",
    "        else:\n",
    "            privacyIndex = 1\n",
    "\n",
    "        return privacyIndex\n",
    "\n",
    "    def calculate_interpretability_index(self):\n",
    "\n",
    "        interIndex = 1\n",
    "\n",
    "        if self.__interpretable_degree__ > .70:\n",
    "            interIndex = 3\n",
    "        elif self.__interpretable_degree__ > .50 and self.__interpretable_degree__ < .70:\n",
    "            interIndex = 2\n",
    "        else:\n",
    "            interIndex = 1\n",
    "\n",
    "        return interIndex\n",
    "\n",
    "    def calculate_bias_index(self):\n",
    "        \n",
    "        if self.__classbalance__ >= 0.4:\n",
    "            bindex = 3\n",
    "        elif self.__classbalance__ > 0.2 and self.__classbalance__ < 0.4:\n",
    "            bindex = 2\n",
    "        else:\n",
    "            bindex = 1\n",
    "\n",
    "        return bindex\n",
    "    \n",
    "    def describe_model(self):\n",
    "        value = json.dumps({\"model name\": self.__modelname__,\n",
    "                    \"framework\": self.__framework__,\n",
    "                    \"emissions\": self.__emissions__,\n",
    "                    \"interpretability\": self.__interpretable_degree__,\n",
    "                    \"privacy\": self.__epsilon__,\n",
    "                    \"bias\": self.__classbalance__,})        \n",
    "        return value\n",
    "    \n",
    "    def model_rai_components(self):\n",
    "        \n",
    "        emission_index = self.calculate_emissions_index()\n",
    "        privacy_index = self.calculate_privacy_index()\n",
    "        bias_index = self.calculate_bias_index()\n",
    "        interpret_index = self.calculate_interpretability_index()\n",
    "        RAI_index = self.rai_index()\n",
    "        \n",
    "        value = json.dumps({\"model name\": self.__modelname__,\n",
    "                            \"framework\": self.__framework__,\n",
    "                            \"rai index\": RAI_index,\n",
    "                            \"emission_index\": emission_index,\n",
    "                            \"privacy_index\": privacy_index,\n",
    "                            \"bias_index\": bias_index,\n",
    "                            \"interpretability_index\": interpret_index})\n",
    "\n",
    "        return value\n",
    "        \n",
    "    def rai_index(self):\n",
    "    \n",
    "        index = 0.0\n",
    "        weights = 0.25\n",
    "\n",
    "        emission_index = self.calculate_emissions_index()\n",
    "        privacy_index = self.calculate_privacy_index()\n",
    "        bias_index = self.calculate_bias_index()\n",
    "        interpret_index = self.calculate_interpretability_index()\n",
    "\n",
    "        index = weights * (emission_index + privacy_index + bias_index + interpret_index)\n",
    "\n",
    "        return index\n",
    "\n",
    "    def track_emissions(self):\n",
    "        # Calculate Emissions\n",
    "        self.__tracker__.start()\n",
    "        \n",
    "    def stop_tracking(self):\n",
    "        self.__emissions__ =  self.__tracker__.stop()\n",
    "        \n",
    "    def calculate_bias(self, df_label: str):\n",
    "        \n",
    "        # Get the number of classes & samples\n",
    "        label_classes = df_label.value_counts(ascending=True)\n",
    "        totalvalues = label_classes.sum()\n",
    "        min_class_count = label_classes.values[1]\n",
    "        \n",
    "        #calcualte the bias\n",
    "        self.__classbalance__ = min_class_count / totalvalues\n",
    "        \n",
    "    def privatize(self, model, optimizer, dataloader, noise_multiplier, max_grad_norm):\n",
    "        \n",
    "        model, optimizer, dataloader = self.__privacy_engine__.make_private(module=model,\n",
    "                                                                            optimizer=optimizer,\n",
    "                                                                            data_loader=dataloader,\n",
    "                                                                            noise_multiplier = noise_multiplier,\n",
    "                                                                            max_grad_norm= max_grad_norm)\n",
    "\n",
    "        return model, optimizer, dataloader\n",
    "        \n",
    "    def calculate_privacy_score(self, delta):\n",
    "        self.__epsilon__ = self.__privacy_engine__.get_epsilon(delta)\n",
    "    \n",
    "    def interpret(self, input_tensor, model,target_class):\n",
    "        \n",
    "        ig = IntegratedGradients(model)\n",
    "        input_tensor.requires_grad_()\n",
    "        attr, delta = ig.attribute(input_tensor,target=target_class, return_convergence_delta=True)\n",
    "        attr = attr.detach().numpy()\n",
    "        importance = np.mean(attr, axis=0)\n",
    "        \n",
    "        importance = np.abs(importance)        \n",
    "        importance[::-1].sort()\n",
    "        \n",
    "        total_weightage = np.sum(importance)\n",
    "        key_features_weightage = importance[0] + importance[1] + importance[2]\n",
    "        \n",
    "        __interpretable_degree__ = key_features_weightage / total_weightage\n",
    "            \n",
    "class models:\n",
    "    model_list = []\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model_list = []\n",
    "    \n",
    "    def add_model(self, modelname, framework, intrepretability, emissions, bias, epsilon):\n",
    "        model = responsibleModel(modelname, framework, intrepretability, emissions, bias, epsilon)\n",
    "        self.model_list.append(model)\n",
    "        \n",
    "    def add_model(self, model):\n",
    "        self.model_list.append(model)\n",
    "        \n",
    "    def remove_model(self, modelname):\n",
    "        self.model_list.remove(modelname)\n",
    "        \n",
    "    def list_models(self):\n",
    "        model_json = \"\"\n",
    "        for model in self.model_list:\n",
    "            model_json += model.describe() \n",
    "            if model != self.model_list[-1]:\n",
    "                model_json += \",\"\n",
    "                                \n",
    "            model_json += \"\\n\"\n",
    "            \n",
    "        model_json = \"[\" + model_json + \"]\"\n",
    "        \n",
    "        return model_json\n",
    "    \n",
    "    def get_model(self, modelname):\n",
    "        for model in self.model_list:\n",
    "            if model.__modelname__ == modelname:\n",
    "                return model\n",
    "        return None\n",
    "    \n",
    "    def rank_models(self, rank_by = \"rai_index\"):\n",
    "        sorted_json = \"\"\n",
    "        \n",
    "        if rank_by == \"rai_index\":\n",
    "            sorted_models = sorted(self.model_list, key=lambda x: x.rai_index(), reverse=True)\n",
    "        elif rank_by == \"emissions\":\n",
    "            sorted_models = sorted(self.model_list, key=lambda x: x.calculate_emissions_index(), reverse=True)\n",
    "        elif rank_by == \"privacy\":\n",
    "            sorted_models = sorted(self.model_list, key=lambda x: x.calculate_privay_index(), reverse=True)\n",
    "        elif rank_by == \"bias\":\n",
    "            sorted_models = sorted(self.model_list, key=lambda x: x.calculate_bias_index(), reverse=True)\n",
    "        elif rank_by == \"interpretability\":\n",
    "            sorted_models = sorted(self.model_list, key=lambda x: x.calculate_interpretability_index(), reverse=True)\n",
    "            \n",
    "        for model in sorted_models:\n",
    "            sorted_json += model.model_rai_components()\n",
    "            if(model != sorted_models[-1]):\n",
    "                sorted_json += \",\"\n",
    "            sorted_json += \"\\n\"\n",
    "            \n",
    "        sorted_json = \"[\" + sorted_json + \"]\"\n",
    "        return sorted_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 14:39:49] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 14:39:49] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 14:39:49] No GPU found.\n",
      "[codecarbon INFO @ 14:39:49] [setup] CPU Tracking...\n",
      "[codecarbon WARNING @ 14:39:49] No CPU tracking mode found. Falling back on CPU constant mode.\n",
      "[codecarbon INFO @ 14:39:51] CPU Model on constant consumption mode: Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz\n",
      "[codecarbon INFO @ 14:39:51] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 14:39:51]   Platform system: Linux-4.14.262-200.489.amzn2.x86_64-x86_64-with-debian-10.6\n",
      "[codecarbon INFO @ 14:39:51]   Python version: 3.7.10\n",
      "[codecarbon INFO @ 14:39:51]   Available RAM : 3.793 GB\n",
      "[codecarbon INFO @ 14:39:51]   CPU count: 2\n",
      "[codecarbon INFO @ 14:39:51]   CPU model: Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz\n",
      "[codecarbon INFO @ 14:39:51]   GPU count: None\n",
      "[codecarbon INFO @ 14:39:51]   GPU model: None\n",
      "/opt/conda/lib/python3.7/site-packages/opacus/privacy_engine.py:115: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n"
     ]
    }
   ],
   "source": [
    "model2 = responsibleModel(modelname = 'test', framework = 'pytorch')\n",
    "model_list = models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target  Pclass   Age  SibSp  Parch     Fare  Sex_female  Sex_male  \\\n",
       "0       0       3  22.0      1      0   7.2500           0         1   \n",
       "1       1       1  38.0      1      0  71.2833           1         0   \n",
       "2       1       3  26.0      0      0   7.9250           1         0   \n",
       "3       1       1  35.0      1      0  53.1000           1         0   \n",
       "4       0       3  35.0      0      0   8.0500           0         1   \n",
       "\n",
       "   Embarked_C  Embarked_Q  Embarked_S  \n",
       "0           0           0           1  \n",
       "1           1           0           0  \n",
       "2           0           0           1  \n",
       "3           0           0           1  \n",
       "4           0           0           1  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data from csv file\n",
    "df = pd.read_csv('../data/titanic.csv')\n",
    "df.drop(['PassengerId', 'Name'], axis=1, inplace=True)\n",
    "\n",
    "categorical_columns = ['Sex', 'Embarked']\n",
    "df_cleaned = pd.get_dummies(df, prefix=categorical_columns)\n",
    "df_cleaned['Age'].fillna(inplace= True, method='bfill' )\n",
    "\n",
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target        0\n",
       "Pclass        0\n",
       "Age           0\n",
       "SibSp         0\n",
       "Parch         0\n",
       "Fare          0\n",
       "Sex_female    0\n",
       "Sex_male      0\n",
       "Embarked_C    0\n",
       "Embarked_Q    0\n",
       "Embarked_S    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting dataframe to numpy array\n",
    "labels = df_cleaned[\"target\"].to_numpy()\n",
    "label_df = df_cleaned[\"target\"]\n",
    "\n",
    "df_cleaned = df_cleaned.drop(['target'], axis=1)\n",
    "feature_names = list(df_cleaned.columns)\n",
    "features = df_cleaned.to_numpy()\n",
    "\n",
    "# loading data into torch tensor\n",
    "feature_tensor = torch.from_numpy(features).type(torch.FloatTensor)\n",
    "label_tensor = torch.from_numpy(labels)\n",
    "\n",
    "# loading data into torch dataset\n",
    "train_dataset = torch.utils.data.TensorDataset(feature_tensor, label_tensor)\n",
    "\n",
    "# loading data into torch dataloader\n",
    "batch_size = 32\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "model2.calculate_bias(label_df)\n",
    "print(model2.calculate_bias_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([891, 10])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TitanicModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(10, 10)\n",
    "        self.sigmoid1 = nn.Sigmoid()\n",
    "        self.linear2 = nn.Linear(10, 8)\n",
    "        self.sigmoid2 = nn.Sigmoid()\n",
    "        self.linear3 = nn.Linear(8, 2)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        lin1_out = self.linear1(x)\n",
    "        sigmoid_out1 = self.sigmoid1(lin1_out)\n",
    "        sigmoid_out2 = self.sigmoid2(self.linear2(sigmoid_out1))\n",
    "        return self.softmax(self.linear3(sigmoid_out2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(trainloader, model, optimizer):\n",
    "    \n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    epochs = 100\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for i, (features, label) in enumerate(train_dataloader):\n",
    "            # Forward pass\n",
    "            y_pred = model(features)\n",
    "            loss = loss_fn(y_pred, label)\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if (i+1) % 10 == 0:\n",
    "                print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                       .format(epoch+1, epochs, i+1, len(train_dataloader), loss.item()))\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start tracking Emissions\n",
    "model2.track_emissions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Step [10/28], Loss: 0.6763\n",
      "Epoch [1/100], Step [20/28], Loss: 0.6801\n",
      "Epoch [2/100], Step [10/28], Loss: 0.6729\n",
      "Epoch [2/100], Step [20/28], Loss: 0.6224\n",
      "Epoch [3/100], Step [10/28], Loss: 0.6716\n",
      "Epoch [3/100], Step [20/28], Loss: 0.6313\n",
      "Epoch [4/100], Step [10/28], Loss: 0.6718\n",
      "Epoch [4/100], Step [20/28], Loss: 0.6658\n",
      "Epoch [5/100], Step [10/28], Loss: 0.6985\n",
      "Epoch [5/100], Step [20/28], Loss: 0.6712\n",
      "Epoch [6/100], Step [10/28], Loss: 0.6517\n",
      "Epoch [6/100], Step [20/28], Loss: 0.6320\n",
      "Epoch [7/100], Step [10/28], Loss: 0.6746\n",
      "Epoch [7/100], Step [20/28], Loss: 0.6665\n",
      "Epoch [8/100], Step [10/28], Loss: 0.6010\n",
      "Epoch [8/100], Step [20/28], Loss: 0.6007\n",
      "Epoch [9/100], Step [10/28], Loss: 0.6452\n",
      "Epoch [9/100], Step [20/28], Loss: 0.6016\n",
      "Epoch [10/100], Step [10/28], Loss: 0.5923\n",
      "Epoch [10/100], Step [20/28], Loss: 0.6465\n",
      "Epoch [11/100], Step [10/28], Loss: 0.6384\n",
      "Epoch [11/100], Step [20/28], Loss: 0.6458\n",
      "Epoch [12/100], Step [10/28], Loss: 0.6823\n",
      "Epoch [12/100], Step [20/28], Loss: 0.5768\n",
      "Epoch [13/100], Step [10/28], Loss: 0.6272\n",
      "Epoch [13/100], Step [20/28], Loss: 0.6365\n",
      "Epoch [14/100], Step [10/28], Loss: 0.5598\n",
      "Epoch [14/100], Step [20/28], Loss: 0.6110\n",
      "Epoch [15/100], Step [10/28], Loss: 0.5958\n",
      "Epoch [15/100], Step [20/28], Loss: 0.5657\n",
      "Epoch [16/100], Step [10/28], Loss: 0.5908\n",
      "Epoch [16/100], Step [20/28], Loss: 0.6085\n",
      "Epoch [17/100], Step [10/28], Loss: 0.5834\n",
      "Epoch [17/100], Step [20/28], Loss: 0.6834\n",
      "Epoch [18/100], Step [10/28], Loss: 0.5867\n",
      "Epoch [18/100], Step [20/28], Loss: 0.6310\n",
      "Epoch [19/100], Step [10/28], Loss: 0.6743\n",
      "Epoch [19/100], Step [20/28], Loss: 0.6015\n",
      "Epoch [20/100], Step [10/28], Loss: 0.6037\n",
      "Epoch [20/100], Step [20/28], Loss: 0.5824\n",
      "Epoch [21/100], Step [10/28], Loss: 0.5565\n",
      "Epoch [21/100], Step [20/28], Loss: 0.6098\n",
      "Epoch [22/100], Step [10/28], Loss: 0.6263\n",
      "Epoch [22/100], Step [20/28], Loss: 0.6097\n",
      "Epoch [23/100], Step [10/28], Loss: 0.6419\n",
      "Epoch [23/100], Step [20/28], Loss: 0.5565\n",
      "Epoch [24/100], Step [10/28], Loss: 0.6174\n",
      "Epoch [24/100], Step [20/28], Loss: 0.5821\n",
      "Epoch [25/100], Step [10/28], Loss: 0.5417\n",
      "Epoch [25/100], Step [20/28], Loss: 0.5744\n",
      "Epoch [26/100], Step [10/28], Loss: 0.5320\n",
      "Epoch [26/100], Step [20/28], Loss: 0.5429\n",
      "Epoch [27/100], Step [10/28], Loss: 0.5801\n",
      "Epoch [27/100], Step [20/28], Loss: 0.5879\n",
      "Epoch [28/100], Step [10/28], Loss: 0.5390\n",
      "Epoch [28/100], Step [20/28], Loss: 0.5610\n",
      "Epoch [29/100], Step [10/28], Loss: 0.5670\n",
      "Epoch [29/100], Step [20/28], Loss: 0.4890\n",
      "Epoch [30/100], Step [10/28], Loss: 0.5068\n",
      "Epoch [30/100], Step [20/28], Loss: 0.5536\n",
      "Epoch [31/100], Step [10/28], Loss: 0.5333\n",
      "Epoch [31/100], Step [20/28], Loss: 0.5679\n",
      "Epoch [32/100], Step [10/28], Loss: 0.5086\n",
      "Epoch [32/100], Step [20/28], Loss: 0.5143\n",
      "Epoch [33/100], Step [10/28], Loss: 0.4702\n",
      "Epoch [33/100], Step [20/28], Loss: 0.4797\n",
      "Epoch [34/100], Step [10/28], Loss: 0.5234\n",
      "Epoch [34/100], Step [20/28], Loss: 0.5929\n",
      "Epoch [35/100], Step [10/28], Loss: 0.5227\n",
      "Epoch [35/100], Step [20/28], Loss: 0.6030\n",
      "Epoch [36/100], Step [10/28], Loss: 0.5494\n",
      "Epoch [36/100], Step [20/28], Loss: 0.4764\n",
      "Epoch [37/100], Step [10/28], Loss: 0.5133\n",
      "Epoch [37/100], Step [20/28], Loss: 0.4905\n",
      "Epoch [38/100], Step [10/28], Loss: 0.5871\n",
      "Epoch [38/100], Step [20/28], Loss: 0.4564\n",
      "Epoch [39/100], Step [10/28], Loss: 0.5018\n",
      "Epoch [39/100], Step [20/28], Loss: 0.6178\n",
      "Epoch [40/100], Step [10/28], Loss: 0.5762\n",
      "Epoch [40/100], Step [20/28], Loss: 0.5173\n",
      "Epoch [41/100], Step [10/28], Loss: 0.4480\n",
      "Epoch [41/100], Step [20/28], Loss: 0.4559\n",
      "Epoch [42/100], Step [10/28], Loss: 0.4912\n",
      "Epoch [42/100], Step [20/28], Loss: 0.6074\n",
      "Epoch [43/100], Step [10/28], Loss: 0.5075\n",
      "Epoch [43/100], Step [20/28], Loss: 0.5055\n",
      "Epoch [44/100], Step [10/28], Loss: 0.5517\n",
      "Epoch [44/100], Step [20/28], Loss: 0.5211\n",
      "Epoch [45/100], Step [10/28], Loss: 0.5457\n",
      "Epoch [45/100], Step [20/28], Loss: 0.5254\n",
      "Epoch [46/100], Step [10/28], Loss: 0.6049\n",
      "Epoch [46/100], Step [20/28], Loss: 0.5469\n",
      "Epoch [47/100], Step [10/28], Loss: 0.5119\n",
      "Epoch [47/100], Step [20/28], Loss: 0.4910\n",
      "Epoch [48/100], Step [10/28], Loss: 0.4715\n",
      "Epoch [48/100], Step [20/28], Loss: 0.4827\n",
      "Epoch [49/100], Step [10/28], Loss: 0.4081\n",
      "Epoch [49/100], Step [20/28], Loss: 0.5419\n",
      "Epoch [50/100], Step [10/28], Loss: 0.4797\n",
      "Epoch [50/100], Step [20/28], Loss: 0.4630\n",
      "Epoch [51/100], Step [10/28], Loss: 0.5560\n",
      "Epoch [51/100], Step [20/28], Loss: 0.5270\n",
      "Epoch [52/100], Step [10/28], Loss: 0.5503\n",
      "Epoch [52/100], Step [20/28], Loss: 0.5483\n",
      "Epoch [53/100], Step [10/28], Loss: 0.4736\n",
      "Epoch [53/100], Step [20/28], Loss: 0.4231\n",
      "Epoch [54/100], Step [10/28], Loss: 0.4619\n",
      "Epoch [54/100], Step [20/28], Loss: 0.4676\n",
      "Epoch [55/100], Step [10/28], Loss: 0.4814\n",
      "Epoch [55/100], Step [20/28], Loss: 0.5032\n",
      "Epoch [56/100], Step [10/28], Loss: 0.3934\n",
      "Epoch [56/100], Step [20/28], Loss: 0.6007\n",
      "Epoch [57/100], Step [10/28], Loss: 0.4681\n",
      "Epoch [57/100], Step [20/28], Loss: 0.6286\n",
      "Epoch [58/100], Step [10/28], Loss: 0.5293\n",
      "Epoch [58/100], Step [20/28], Loss: 0.4628\n",
      "Epoch [59/100], Step [10/28], Loss: 0.6237\n",
      "Epoch [59/100], Step [20/28], Loss: 0.4783\n",
      "Epoch [60/100], Step [10/28], Loss: 0.5200\n",
      "Epoch [60/100], Step [20/28], Loss: 0.4814\n",
      "Epoch [61/100], Step [10/28], Loss: 0.5373\n",
      "Epoch [61/100], Step [20/28], Loss: 0.5111\n",
      "Epoch [62/100], Step [10/28], Loss: 0.5042\n",
      "Epoch [62/100], Step [20/28], Loss: 0.4436\n",
      "Epoch [63/100], Step [10/28], Loss: 0.4673\n",
      "Epoch [63/100], Step [20/28], Loss: 0.5397\n",
      "Epoch [64/100], Step [10/28], Loss: 0.5494\n",
      "Epoch [64/100], Step [20/28], Loss: 0.5356\n",
      "Epoch [65/100], Step [10/28], Loss: 0.5073\n",
      "Epoch [65/100], Step [20/28], Loss: 0.5091\n",
      "Epoch [66/100], Step [10/28], Loss: 0.4358\n",
      "Epoch [66/100], Step [20/28], Loss: 0.5173\n",
      "Epoch [67/100], Step [10/28], Loss: 0.5713\n",
      "Epoch [67/100], Step [20/28], Loss: 0.5356\n",
      "Epoch [68/100], Step [10/28], Loss: 0.5638\n",
      "Epoch [68/100], Step [20/28], Loss: 0.4966\n",
      "Epoch [69/100], Step [10/28], Loss: 0.5319\n",
      "Epoch [69/100], Step [20/28], Loss: 0.5294\n",
      "Epoch [70/100], Step [10/28], Loss: 0.5014\n",
      "Epoch [70/100], Step [20/28], Loss: 0.4526\n",
      "Epoch [71/100], Step [10/28], Loss: 0.5354\n",
      "Epoch [71/100], Step [20/28], Loss: 0.5137\n",
      "Epoch [72/100], Step [10/28], Loss: 0.4427\n",
      "Epoch [72/100], Step [20/28], Loss: 0.4945\n",
      "Epoch [73/100], Step [10/28], Loss: 0.5831\n",
      "Epoch [73/100], Step [20/28], Loss: 0.5460\n",
      "Epoch [74/100], Step [10/28], Loss: 0.5353\n",
      "Epoch [74/100], Step [20/28], Loss: 0.4591\n",
      "Epoch [75/100], Step [10/28], Loss: 0.4920\n",
      "Epoch [75/100], Step [20/28], Loss: 0.5846\n",
      "Epoch [76/100], Step [10/28], Loss: 0.5202\n",
      "Epoch [76/100], Step [20/28], Loss: 0.4372\n",
      "Epoch [77/100], Step [10/28], Loss: 0.5265\n",
      "Epoch [77/100], Step [20/28], Loss: 0.4773\n",
      "Epoch [78/100], Step [10/28], Loss: 0.5244\n",
      "Epoch [78/100], Step [20/28], Loss: 0.4527\n",
      "Epoch [79/100], Step [10/28], Loss: 0.5007\n",
      "Epoch [79/100], Step [20/28], Loss: 0.5223\n",
      "Epoch [80/100], Step [10/28], Loss: 0.4352\n",
      "Epoch [80/100], Step [20/28], Loss: 0.6029\n",
      "Epoch [81/100], Step [10/28], Loss: 0.4809\n",
      "Epoch [81/100], Step [20/28], Loss: 0.5836\n",
      "Epoch [82/100], Step [10/28], Loss: 0.4760\n",
      "Epoch [82/100], Step [20/28], Loss: 0.4678\n",
      "Epoch [83/100], Step [10/28], Loss: 0.5751\n",
      "Epoch [83/100], Step [20/28], Loss: 0.4913\n",
      "Epoch [84/100], Step [10/28], Loss: 0.5189\n",
      "Epoch [84/100], Step [20/28], Loss: 0.6097\n",
      "Epoch [85/100], Step [10/28], Loss: 0.5381\n",
      "Epoch [85/100], Step [20/28], Loss: 0.4365\n",
      "Epoch [86/100], Step [10/28], Loss: 0.4525\n",
      "Epoch [86/100], Step [20/28], Loss: 0.5441\n",
      "Epoch [87/100], Step [10/28], Loss: 0.5343\n",
      "Epoch [87/100], Step [20/28], Loss: 0.5484\n",
      "Epoch [88/100], Step [10/28], Loss: 0.4428\n",
      "Epoch [88/100], Step [20/28], Loss: 0.6855\n",
      "Epoch [89/100], Step [10/28], Loss: 0.5046\n",
      "Epoch [89/100], Step [20/28], Loss: 0.5267\n",
      "Epoch [90/100], Step [10/28], Loss: 0.5527\n",
      "Epoch [90/100], Step [20/28], Loss: 0.5693\n",
      "Epoch [91/100], Step [10/28], Loss: 0.5400\n",
      "Epoch [91/100], Step [20/28], Loss: 0.4486\n",
      "Epoch [92/100], Step [10/28], Loss: 0.5050\n",
      "Epoch [92/100], Step [20/28], Loss: 0.5342\n",
      "Epoch [93/100], Step [10/28], Loss: 0.4621\n",
      "Epoch [93/100], Step [20/28], Loss: 0.6140\n",
      "Epoch [94/100], Step [10/28], Loss: 0.4828\n",
      "Epoch [94/100], Step [20/28], Loss: 0.4514\n",
      "Epoch [95/100], Step [10/28], Loss: 0.3909\n",
      "Epoch [95/100], Step [20/28], Loss: 0.4738\n",
      "Epoch [96/100], Step [10/28], Loss: 0.4447\n",
      "Epoch [96/100], Step [20/28], Loss: 0.3924\n",
      "Epoch [97/100], Step [10/28], Loss: 0.5380\n",
      "Epoch [97/100], Step [20/28], Loss: 0.5374\n",
      "Epoch [98/100], Step [10/28], Loss: 0.4081\n",
      "Epoch [98/100], Step [20/28], Loss: 0.5132\n",
      "Epoch [99/100], Step [10/28], Loss: 0.4352\n",
      "Epoch [99/100], Step [20/28], Loss: 0.4685\n",
      "Epoch [100/100], Step [10/28], Loss: 0.5992\n",
      "Epoch [100/100], Step [20/28], Loss: 0.4972\n"
     ]
    }
   ],
   "source": [
    "vanilla_model = TitanicModel()\n",
    "\n",
    "optimizer = torch.optim.Adam(vanilla_model.parameters(), lr=0.001)\n",
    "\n",
    "trained_vanilla_model = train(train_dataloader, vanilla_model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 14:40:16] Energy consumed for RAM : 0.000004 kWh. RAM Power : 1.4222803115844729 W\n",
      "[codecarbon INFO @ 14:40:16] Energy consumed for all CPUs : 0.000259 kWh. All CPUs Power : 105.0 W\n",
      "[codecarbon INFO @ 14:40:16] 0.000263 kWh of electricity used since the begining.\n"
     ]
    }
   ],
   "source": [
    "model2.stop_tracking()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(model2.calculate_emissions_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.interpret(feature_tensor, trained_vanilla_model, target_class=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(model2.calculate_interpretability_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py:1033: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "04/29/2022 19:20:54:INFO:Despite set_to_none is set to False, opacus will set p.grad_sample and p.summed_grad to None due to non-trivial gradient accumulation behaviour\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Poisson sampling is not compatible with grad accumulation. You need to call optimizer.step() after every forward/backward pass or consider using BatchMemoryManager",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-119-488d7d8e70e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mpriv_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpriv_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpriv_datasetloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprivatize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdp_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_multiplier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_per_sample_grad_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtrained_dp_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpriv_datasetloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpriv_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpriv_opt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-111-c9dafc596154>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(trainloader, model, optimizer)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1115\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_global_forward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0m_global_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1118\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/opacus/privacy_engine.py\u001b[0m in \u001b[0;36mforbid_accumulation_hook\u001b[0;34m(module, _input)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_sample\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             raise ValueError(\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0;34m\"Poisson sampling is not compatible with grad accumulation. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m                 \u001b[0;34m\"You need to call optimizer.step() after every forward/backward pass \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                 \u001b[0;34m\"or consider using BatchMemoryManager\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Poisson sampling is not compatible with grad accumulation. You need to call optimizer.step() after every forward/backward pass or consider using BatchMemoryManager"
     ]
    }
   ],
   "source": [
    "noise_multiplier = 5\n",
    "max_per_sample_grad_norm = 1.5\n",
    "sample_rate = batch_size/len(train_dataset)\n",
    "\n",
    "dp_model = TitanicModel()\n",
    "\n",
    "optimizer = optim.Adam(dp_model.parameters(), weight_decay=0.0001, lr=0.003)\n",
    "\n",
    "priv_model, priv_opt, priv_datasetloader = model2.privatize(dp_model, optimizer, train_dataloader, noise_multiplier, max_per_sample_grad_norm)\n",
    "\n",
    "trained_dp_model = train(priv_datasetloader, priv_model, priv_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/opacus/accountants/analysis/rdp.py:333: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  f\"Optimal order is the {extreme} alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\"\n"
     ]
    }
   ],
   "source": [
    "# Calculate Differential Privacy\n",
    "model2.calculate_privacy_score(delta=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"model name\": \"test\", \"framework\": \"pytorch\", \"emissions\": 7.962479560578028e-05, \"explained\": false, \"privacy\": 0.10466829124801816, \"bias\": 0.6161616161616161}'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list.add_model(model = model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model name</th>\n",
       "      <th>framework</th>\n",
       "      <th>rai index</th>\n",
       "      <th>emission_index</th>\n",
       "      <th>privacy_index</th>\n",
       "      <th>bias_index</th>\n",
       "      <th>explainability_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>2.75</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model name framework  rai index  emission_index  privacy_index  bias_index  \\\n",
       "0       test   pytorch       2.75               3              3           3   \n",
       "\n",
       "   explainability_index  \n",
       "0                     2  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_json = model_list.rank_models()\n",
    "\n",
    "jdata = json.loads(models_json)\n",
    "df = pd.DataFrame(jdata)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
